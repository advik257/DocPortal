import os
import sys
import uuid # data versioning
from pathlib import Path
from datetime import datetime
from operator import itemgetter
from typing import Optional,List

from logger.custom_logger import CustomLogger
from exception.custom_exception_archive import DocumentPortalException
from utils.model_loader import  ModelLoader
from prompt.prompt_library import PROMPT_REGISTRY
from model.models import *

from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,BaseMessage
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.vectorstores import FAISS



class ConversationalRAG:
    

    
    def __init__(self, session_id:str , retriever =None):
        
        try:
            self.log = CustomLogger().get_logger(__name__)
            self.session_id = session_id or f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
            #self.retriever = retriever
            self.llm = self._load_llm()
            self.contextuliaze_prompt = PROMPT_REGISTRY[promptType.CONTEXTULIZE_QUSTION.value]
            self.qa_prompt = PROMPT_REGISTRY[promptType.CONTEXT_QA.value]
            
            if retriever is None:
                raise ValueError("Retriever cannot be None for ConversationalRAG.")
            
            self.retriever = retriever
            self._build_lcel_chain()
            self.log.info("ConversationalRAG initialized successfully." , session_id=self.session_id)
            
        except Exception as e:
            self.log.error("Error initializing Multi doc ConversationalRAG:", error=str(e))
            raise DocumentPortalException("Failed to initialize ConversationalRAG", sys)
        
    
    def load_retriever_from_faiss(self,index_path:str):
        
        """Load a FAISS vector store from disk and convert to a retriever """
        try:
            self.model_loader = ModelLoader().load_embeddings()
            if not os.path.exists(index_path):
                raise FileNotFoundError(f"FAISS index not found at path: {index_path}")
            
            FAISS.load_local(folder_path=index_path, embeddings=self.model_loader,allow_dangerous_deserialization=True)
            retriever = self.vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
            self.log.info("Retriever loaded from FAISS index successfully.", index_path=index_path)
            
            
            return self.retriever
            
        except Exception as e:
            self.log.error("Error loading retriever from FAISS:", error=str(e))
            raise DocumentPortalException("Failed to load retriever from FAISS", sys)
    
    def invoke(self, user_input:str, chat_history:Optional[list[BaseMessage]] =None)-> str:
        
        """Invoke the Conversational RAG chain with a user question.
        Args:
            user_input (str): The user's question.
            chat_history (Optional[list[BaseMessage]]): The chat history as a list of BaseMessage objects.
        
        """
        try:
            chat_history = chat_history or []
            # Prepare input payload
            payload = {
                "question": str(user_input).strip(),  # Ensure string and remove whitespace
                "chat_history": chat_history
            }
            self.log.info("Processing question",question=payload["question"],history_length=len(chat_history))
            
             # Invoke chain
            answer = self.chain.invoke(payload)
            
            if not answer:
                self.log.warning("No answer generated by the Conversational RAG chain.")
                return "No Answer Found"
            self.log.info("Conversational RAG invoked successfully.", user_input=user_input, answer=answer)
            
            return answer.strip()
        
        except Exception as e:
            self.log.error("Error invoking ConversationalRAG:", error=str(e))
            raise DocumentPortalException("Failed to invoke ConversationalRAG", sys)
    
    def _load_llm(self):
        """Load the language model for generating responses."""
        try:
            model_loader = ModelLoader()
            llm = model_loader.load_llm()
            if not llm:
                raise ValueError("LLM could not be loaded.")
            self.log.info("LLM loaded successfully.")
            return llm
        except Exception as e:
            self.log.error("Error loading LLM:", error=str(e))
            raise DocumentPortalException("Failed to load LLM", sys)
    
    @staticmethod
    def _format_docs(docs):
        """Format retrieved documents for prompt input."""
        return "\n\n".join(d.page_content for d in docs)
       
    
    def _build_lcel_chain(self):
        """Build the LCEL chain for conversational RAG."""
        try:
            
            # Question rewriting chain to get standalone question
            question_rewriter = (
                {
                    "input": itemgetter("question"), 
                    "chat_history": itemgetter("chat_history")
                }
                | self.contextuliaze_prompt
                | self.llm
                | StrOutputParser()
            )
            
            # Retrieval chain with formatted docs
            retrieve_and_format = (
                itemgetter("question")  # Get question string
                | self.retriever  # Get relevant docs
                | self._format_docs  # Format docs into string
            )
            
            # Final QA chain combining context and question
            self.chain = (
                {
                    "context": retrieve_and_format,
                    "input": question_rewriter,
                    "chat_history": itemgetter("chat_history")
                }
                | self.qa_prompt
                | self.llm
                | StrOutputParser()
            )
            
            self.log.info("LCEL chain built successfully")
            
        except Exception as e:
            self.log.error(
                "Error building LCEL chain",
                error=str(e),
                error_type=type(e).__name__
            )
            raise DocumentPortalException("Failed to build LCEL chain", sys)
    